function response = call_llm_api(prompt, config)
    try
        response = webwrite('https://api.openai.com/v1/chat/completions', ...
            struct('model', config.model, ...
                   'messages', {[struct('role', 'user', 'content', prompt)]}, ...
                   'temperature', config.temperature), ...
            weboptions('HeaderFields', {'Authorization', ['Bearer ' config.api_key], ...
                                      'Content-Type', 'application/json'}));
        response = response.choices(1).message.content;
    catch e
        warning('LLM API call failed: %s', e.message);
        response = '';
    end
end 